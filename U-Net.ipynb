{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def data_loader():\n",
    "  # Specify the directories for the input data X and teh target images y\n",
    "  X_dir = \"data/images/\"\n",
    "  y_dir = \"data/masks/\"\n",
    "  \n",
    "  # Fetch images using pillow, convert to tensors, and stack in torch tensor\n",
    "  X = torch.stack([transforms.PILToTensor()(Image.open(X_dir+f)) for f in os.listdir(X_dir)])\n",
    "  y = torch.stack([transforms.PILToTensor()(Image.open(y_dir+f)) for f in os.listdir(y_dir)])\n",
    "  \n",
    "  # Return X and y (the masks) as a tensor of 0 and 1 values\n",
    "  #   The reason for this is that y is fromm 0 to 255 so we need\n",
    "  #   to convert this to binary values (0 or 1, car or background)\n",
    "  return X,(y>50).long()\n",
    "\n",
    "\n",
    "imgs,labels = data_loader()\n",
    "\n",
    "# Split the data into train and test sets\n",
    "imgs_train, imgs_test, labels_train, labels_test = train_test_split(\n",
    "    imgs, labels, test_size=0.2, random_state=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch random image and mask\n",
    "idx = np.random.randint(0, np.shape(imgs))[0]\n",
    "single_digit = imgs[idx]\n",
    "single_label = labels[idx]\n",
    "\n",
    "# Display the image, the mask, and a combination of the two\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1, 3, figsize=(15,15))\n",
    "\n",
    "ax1.title.set_text('Car Image in Single Band')\n",
    "ax1.imshow(single_digit.squeeze(), )\n",
    "ax2.title.set_text('Target Mask')\n",
    "ax2.imshow(single_label.squeeze(), cmap=\"Greys\")\n",
    "ax3.title.set_text('Target Mask placed over Image')\n",
    "ax3.imshow(single_digit.squeeze(), )\n",
    "ax3.imshow(single_label.squeeze(), cmap=\"Greys\",  alpha=0.7)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU capability\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "  device = torch.device(\"cuda\") # GPU\n",
    "else:\n",
    "  device = torch.device(\"cpu\") # CPU\n",
    "    \n",
    "print(f\"Running PyTorch Using: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eff670",
   "metadata": {},
   "source": [
    "Now we'll prepare our data for training and testing using Pytorch's DataLoader which will pass in samples in “minibatches” and reshuffle the data at every epoch to reduce model overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size for training\n",
    "batch_size = 1\n",
    "\n",
    "# A lambda function to prepare tensors for the GPU capability in the dataloaders\n",
    "to_device = lambda a: a.to(device)\n",
    "\n",
    "# Create data loaders for train and test datasets\n",
    "train_loader = data_utils.DataLoader(\n",
    "  data_utils.TensorDataset(to_device(imgs_train), to_device(labels_train)),\n",
    "  batch_size = batch_size,\n",
    "  shuffle = True\n",
    ")\n",
    "\n",
    "test_loader = data_utils.DataLoader(\n",
    "  data_utils.TensorDataset(to_device(imgs_test), to_device(labels_test)),\n",
    "  batch_size = batch_size,\n",
    "  shuffle = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd841210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This double convolution operation is repeated through the network, \n",
    "# so package it for repeated use:\n",
    "class DoubleConv(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super(DoubleConv, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the U-Net architecture as a sub-class of torch.nn.Module\n",
    "class UNET(nn.Module):\n",
    "  def __init__(\n",
    "    self, \n",
    "    in_channels=1, # number of channels in the input\n",
    "    out_channels=2, # number of channels in the output\n",
    "    features=[64, 128, 256, 512] # number of features at each layer in the network\n",
    "  ):\n",
    "    super(UNET, self).__init__()\n",
    "    self.ups = nn.ModuleList()  # operations in the contracting path\n",
    "    self.downs = nn.ModuleList()  # operations in the expanding path\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # the max pooling operation\n",
    "\n",
    "    # Contracting part of UNET\n",
    "    for feature in features:\n",
    "      self.downs.append(DoubleConv(in_channels, feature))\n",
    "      in_channels = feature\n",
    "\n",
    "    # Expanding part of UNET\n",
    "    for feature in reversed(features):\n",
    "      self.ups.append(\n",
    "        nn.ConvTranspose2d(\n",
    "          feature*2, feature, kernel_size=2, stride=2,\n",
    "        )\n",
    "      )\n",
    "      self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "    # Define the bottom of the network and the final convolution\n",
    "    self.network_bottom = DoubleConv(features[-1], features[-1]*2)\n",
    "    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    skip_connections = []\n",
    "\n",
    "    # Iterate through the contracting convolutions and max-pooling\n",
    "    for down in self.downs:\n",
    "      x = down(x)\n",
    "      skip_connections.append(x)\n",
    "      x = self.pool(x)\n",
    "\n",
    "    # Go through the bottom of the network\n",
    "    x = self.network_bottom(x)\n",
    "    # Reverse the order of skip connections\n",
    "    skip_connections = skip_connections[::-1]\n",
    "\n",
    "    # Iterate through the expanding portion of the network\n",
    "    for idx in range(0, len(self.ups), 2):\n",
    "      x = self.ups[idx](x)\n",
    "      skip_connection = skip_connections[idx//2]\n",
    "\n",
    "      if x.shape != skip_connection.shape:\n",
    "        x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "      # Add the skip connection data from the contracting path\n",
    "      concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "      x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "    # Perform the final convolution to 2 classes\n",
    "    x = self.final_conv(x)\n",
    "    # Perform softmax\n",
    "    x = nn.Softmax(dim=1)(x)\n",
    "    # Return the max value so the output image is labeled (0,1) like the target label images\n",
    "    return torch.argmax(x, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef081397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for training a model...\n",
    "def train_model(\n",
    "  model, \n",
    "  train_data, \n",
    "  test_data, \n",
    "  optimizer, \n",
    "  error_func, \n",
    "  n_epochs, \n",
    "  augment_method=None, \n",
    "  print_every=1\n",
    "):\n",
    "  for epoch_i in range(1, n_epochs + 1):\n",
    "    for i, (img, label) in enumerate(train_data, 1):\n",
    "      model.zero_grad()\n",
    "      predicted = model.forward(img.float())\n",
    "      loss = error_func(predicted.float().requires_grad_(), label[0].to(torch.float))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      if((i % print_every == 0) or (i == len(train_data))):\n",
    "        print(f\"Epoch: {epoch_i}/{n_epochs}, Iter: {i}/{len(train_data)}, Loss: {loss:.04f}\")\n",
    "            \n",
    "    # Run against the test set and train set at the end of each epoch to get accuracy...\n",
    "    acc1 = get_accuracy(model, train_data, augment_method)\n",
    "    print(f\"Epoch {epoch_i} Train Accuracy: {acc1 * 100:.02f}%\")\n",
    "    acc2 = get_accuracy(model, test_data, augment_method)\n",
    "    print(f\"Epoch {epoch_i} Test Accuracy: {acc2 * 100:.02f}%\\n\")\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "def get_accuracy(model, data, im_mod = None):\n",
    "  run = 0\n",
    "  correct = 0\n",
    "\n",
    "  for count, (img, label) in enumerate(data, 1):\n",
    "    run += len(img)\n",
    "    result = model.forward(img.float()).cpu().detach().numpy()\n",
    "    correct += np.sum(np.argmax(result, axis=1) == label.cpu().detach().numpy())\n",
    "    print(\"Validation at {:.2f}%\".format(count/len(data)*100.),end='\\r')\n",
    "\n",
    "  return correct / run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "unet_model = UNET(in_channels=1, out_channels=2)\n",
    "\n",
    "# Initialize model hyperparameters \n",
    "n_epochs = 2\n",
    "lr = 1e-4\n",
    "optimizer = optim.SGD(unet_model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79951834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "res_net = train_model(unet_model, train_loader, test_loader, optimizer, loss_func, n_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
